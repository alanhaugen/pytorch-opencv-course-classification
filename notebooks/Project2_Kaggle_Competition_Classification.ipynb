{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods that will be used to get training and validation data loader.\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "def get_data(args1, *agrs):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics libraries for python\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesArray = [] # hack\n",
    "        \n",
    "class FoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This custom dataset class take root directory and train flag, \n",
    "    and return dataset training dataset id train flag is true \n",
    "    else is return validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, train=True, image_shape=None, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        init method of the class.\n",
    "        \n",
    "         Parameters:\n",
    "         \n",
    "         data_root (string): path of root directory.\n",
    "         \n",
    "         train (boolean): True for training dataset and False for test dataset.\n",
    "         \n",
    "         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n",
    "                                             It is not None image will resize to the given shape.\n",
    "                                 \n",
    "         transform (method): method that will take PIL image and transforms it.\n",
    "         \n",
    "        \"\"\"\n",
    "        \n",
    "        # get label to class mapping\n",
    "        if train:\n",
    "            label_csv_path = os.path.join(data_root, 'train.csv')\n",
    "        else:\n",
    "            label_csv_path = os.path.join(data_root, 'sample_submission.csv') # test.csv? Does not have classes...\n",
    "        \n",
    "        img_dir = os.path.join(data_root, 'images', 'images')\n",
    "        \n",
    "        self.label_df = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "        \n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "            'label': []\n",
    "        }\n",
    "        \n",
    "        # Dirty. Maybe train_test_split from sklearn would be a better option\n",
    "        for i, table in self.label_df.iterrows():\n",
    "            img = table['id']\n",
    "            className = table['class']\n",
    "            if className not in classesArray:\n",
    "                classesArray.append(className)\n",
    "            classNumber = classesArray.index(className)\n",
    "            img_path  = os.path.join(img_dir, str(img) + '.jpg')\n",
    "            self.data_dict['image_path'].append(img_path)\n",
    "            self.data_dict['label'].append(classNumber)\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['label'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        image = Image.open(self.data_dict['image_path'][idx])\n",
    "        \n",
    "        if self.image_shape is not None:\n",
    "            image = image.resize(self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        target = self.data_dict['label'][idx]\n",
    "        \n",
    "        return image, target            \n",
    "                \n",
    "        \n",
    "    def get_id(self, label):\n",
    "        \"\"\"\n",
    "        class label to common name mapping\n",
    "        \"\"\"\n",
    "        return self.label_df['id'][label]\n",
    "    \n",
    "    def get_class(self, label):\n",
    "        \"\"\"\n",
    "        class label to latin name mapping\n",
    "        \"\"\"\n",
    "        return self.label_df['class'][label]\n",
    "\n",
    "def get_data(batch_size, data_root, num_workers=4, data_augmentation=False):\n",
    "    mean, std = get_mean_std(data_root=data_root, num_workers=num_workers)\n",
    "    \n",
    "    common_transforms = image_common_transforms(mean, std)\n",
    "   \n",
    "    # if data_augmentation is true \n",
    "    # data augmentation implementation\n",
    "    if data_augmentation:    \n",
    "        train_transforms = data_augmentation_preprocess(mean, std)\n",
    "    # else do common transforms\n",
    "    else:\n",
    "        train_transforms = common_transforms\n",
    "    \n",
    "       \n",
    "    # train dataloader\n",
    "    \n",
    "    trainDataset = FoodDataset(data_root, train=True, image_shape=256, transform=train_transforms)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(trainDataset, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True,\n",
    "                               num_workers=num_workers)\n",
    "    \n",
    "    # test dataloader\n",
    "    \n",
    "    testDataset = FoodDataset(data_root, train=False, image_shape=256, transform=train_transforms)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(testDataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=num_workers)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "Define your configuration in this section.\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"./cat-dog-panda\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 100  # number of times the whole dataset will be passed through the network\n",
    "    init_learning_rate: float = 0.0001  # determines the speed of network's weights update\n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"data_proj2\" \n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "Define methods or classes that will be used in model evaluation—for example, accuracy, f1-score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, colors, \n",
    "                       loss_legend_loc='upper center', acc_legend_loc='upper left', \n",
    "                       fig_size=(20, 10), sub_plot1=(1, 2, 1), sub_plot2=(1, 2, 2)):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n",
    "    \n",
    "    for i in range(len(train_loss)):\n",
    "        x_train = range(len(train_loss[i]))\n",
    "        x_val = range(len(val_loss[i]))\n",
    "        \n",
    "        min_train_loss = train_loss[i].min()\n",
    "        \n",
    "        min_val_loss = val_loss[i].min()\n",
    "        \n",
    "        plt.plot(x_train, train_loss[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN LOSS ({0:.4})\".format(min_train_loss))\n",
    "        plt.plot(x_val, val_loss[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID LOSS ({0:.4})\".format(min_val_loss))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc=loss_legend_loc)\n",
    "    plt.title('Training and Validation Loss')\n",
    "        \n",
    "    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n",
    "    \n",
    "    for i in range(len(train_acc)):\n",
    "        x_train = range(len(train_acc[i]))\n",
    "        x_val = range(len(val_acc[i]))\n",
    "        \n",
    "        max_train_acc = train_acc[i].max() \n",
    "        \n",
    "        max_val_acc = val_acc[i].max() \n",
    "        \n",
    "        plt.plot(x_train, train_acc[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN ACC ({0:.4})\".format(max_train_acc))\n",
    "        plt.plot(x_val, val_acc[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID ACC ({0:.4})\".format(max_val_acc))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=acc_legend_loc)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    fig.savefig('sample_loss_acc_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='models', model_file_name='food_classifier.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='models', model_file_name='food_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "Write the methods or classes that will be used for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    # \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "       \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "    \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "Define your model in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 256x256x3\n",
    "classes = 13\n",
    "nodes = 128\n",
    "k = 1\n",
    "\n",
    "#nn.BatchNorm2d(64),\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(16 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16 * k, out_channels=32 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(32 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32 * k, out_channels=64 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(64 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64 * k, out_channels=128 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(128 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128 * k, out_channels=nodes * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(nodes * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Linear(in_features=3200 * k, out_features=10), \n",
    "            nn.Dropout(0.5), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=10, out_features=classes)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='models', model_file_name='food_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, scheduler=None, system_configuration=SystemConfiguration(), \n",
    "         training_configuration=TrainingConfiguration(), data_augmentation=True):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 4\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set,\n",
    "        data_augmentation=data_augmentation\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "#         Calculate Initial Test Loss\n",
    "        init_val_loss, init_val_accuracy = validate(training_configuration, model, test_loader)\n",
    "        print(\"Initial Test Loss : {:.6f}, \\nInitial Test Accuracy : {:.3f}%\\n\".format(init_val_loss, init_val_accuracy*100))\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Decay learning rate\n",
    "        scheduler.step() # Not sure if this is in the right place\n",
    "        print('Stepping scheduler this epoch. ', 'LR:', scheduler.get_lr())\n",
    "\n",
    "        # Validate\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Model Improved. Saving the Model...\\n')\n",
    "                save_model(model, device=training_configuration.device)\n",
    "        \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "Define your methods or classes which are not covered in the above sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms():\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms\n",
    "\n",
    "def data_augmentation_preprocess(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    data_augmentation_transforms = transforms.Compose([\n",
    "        torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomRotation(20),\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return data_augmentation_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(data_root, num_workers=4):\n",
    "    \n",
    "    transform = image_preprocess_transforms()\n",
    "    training_configuration = TrainingConfiguration()\n",
    "    \n",
    "    file_path = os.path.join(data_root, 'images')\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=file_path, transform=transform)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=training_configuration.batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "    \n",
    "    print('mean: {}, std: {}'.format(mean, std))\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "Choose your optimizer and LR-scheduler and use the above methods and classes to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=3200, out_features=10, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=10, out_features=13, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "#model = torchvision.models.resnet50()\n",
    "\n",
    "print(model)\n",
    "\n",
    "# get optimizer\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=train_config.init_learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# optimizer\n",
    "#optimizer = optim.Adam(\n",
    "#    model.parameters(),\n",
    "#    lr = train_config.init_learning_rate\n",
    "#)\n",
    "\n",
    "#scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "decayRate = 0.96\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decayRate)\n",
    "\n",
    "#optimizer = optim.SGD(\n",
    "#    model.parameters(),\n",
    "#    lr=train_config.init_learning_rate\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.5767, 0.4626, 0.3468]), std: tensor([0.2383, 0.2463, 0.2465])\n",
      "\n",
      "Test set: Average loss: 2.5782, Accuracy: 138/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.578185, \n",
      "Initial Test Accuracy : 8.425%\n",
      "\n",
      "Epoch: 0 \n",
      "Train Loss: 2.509543 Acc: 0.1405\n",
      "Elapsed 50.66s, 50.66 s/epoch, 0.25 s/batch, ets 5015.36s\n",
      "Stepping scheduler this epoch.  LR: [9.216e-05]\n",
      "\n",
      "Test set: Average loss: 2.6316, Accuracy: 137/1638 (8%)\n",
      "\n",
      "Model Improved. Saving the Model...\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6284, Accuracy: 139/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.628350, \n",
      "Initial Test Accuracy : 8.486%\n",
      "\n",
      "Epoch: 1 \n",
      "Train Loss: 2.453276 Acc: 0.1662\n",
      "Elapsed 113.06s, 56.53 s/epoch, 0.28 s/batch, ets 5540.07s\n",
      "Stepping scheduler this epoch.  LR: [8.847359999999999e-05]\n",
      "\n",
      "Test set: Average loss: 2.6600, Accuracy: 143/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6525, Accuracy: 142/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.652509, \n",
      "Initial Test Accuracy : 8.669%\n",
      "\n",
      "Epoch: 2 \n",
      "Train Loss: 2.442181 Acc: 0.1623\n",
      "Elapsed 174.58s, 58.19 s/epoch, 0.28 s/batch, ets 5644.65s\n",
      "Stepping scheduler this epoch.  LR: [8.493465599999999e-05]\n",
      "\n",
      "Test set: Average loss: 2.6478, Accuracy: 139/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6359, Accuracy: 154/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.635928, \n",
      "Initial Test Accuracy : 9.402%\n",
      "\n",
      "Epoch: 3 \n",
      "Train Loss: 2.421760 Acc: 0.1755\n",
      "Elapsed 236.31s, 59.08 s/epoch, 0.29 s/batch, ets 5671.54s\n",
      "Stepping scheduler this epoch.  LR: [8.153726975999998e-05]\n",
      "\n",
      "Test set: Average loss: 2.6607, Accuracy: 146/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6638, Accuracy: 141/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.663783, \n",
      "Initial Test Accuracy : 8.608%\n",
      "\n",
      "Epoch: 4 \n",
      "Train Loss: 2.400529 Acc: 0.1895\n",
      "Elapsed 297.16s, 59.43 s/epoch, 0.29 s/batch, ets 5646.02s\n",
      "Stepping scheduler this epoch.  LR: [7.827577896959998e-05]\n",
      "\n",
      "Test set: Average loss: 2.6634, Accuracy: 158/1638 (10%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6649, Accuracy: 152/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.664934, \n",
      "Initial Test Accuracy : 9.280%\n",
      "\n",
      "Epoch: 5 \n",
      "Train Loss: 2.383852 Acc: 0.1905\n",
      "Elapsed 357.85s, 59.64 s/epoch, 0.29 s/batch, ets 5606.24s\n",
      "Stepping scheduler this epoch.  LR: [7.514474781081598e-05]\n",
      "\n",
      "Test set: Average loss: 2.7012, Accuracy: 135/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6963, Accuracy: 133/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.696347, \n",
      "Initial Test Accuracy : 8.120%\n",
      "\n",
      "Epoch: 6 \n",
      "Train Loss: 2.385425 Acc: 0.1968\n",
      "Elapsed 420.48s, 60.07 s/epoch, 0.29 s/batch, ets 5586.35s\n",
      "Stepping scheduler this epoch.  LR: [7.213895789838334e-05]\n",
      "\n",
      "Test set: Average loss: 2.7050, Accuracy: 153/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7007, Accuracy: 138/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.700662, \n",
      "Initial Test Accuracy : 8.425%\n",
      "\n",
      "Epoch: 7 \n",
      "Train Loss: 2.371542 Acc: 0.2029\n",
      "Elapsed 481.50s, 60.19 s/epoch, 0.29 s/batch, ets 5537.24s\n",
      "Stepping scheduler this epoch.  LR: [6.9253399582448e-05]\n",
      "\n",
      "Test set: Average loss: 2.6644, Accuracy: 155/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6636, Accuracy: 161/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.663578, \n",
      "Initial Test Accuracy : 9.829%\n",
      "\n",
      "Epoch: 8 \n",
      "Train Loss: 2.363178 Acc: 0.2020\n",
      "Elapsed 542.54s, 60.28 s/epoch, 0.29 s/batch, ets 5485.69s\n",
      "Stepping scheduler this epoch.  LR: [6.648326359915008e-05]\n",
      "\n",
      "Test set: Average loss: 2.6736, Accuracy: 158/1638 (10%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6781, Accuracy: 154/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.678111, \n",
      "Initial Test Accuracy : 9.402%\n",
      "\n",
      "Epoch: 9 \n",
      "Train Loss: 2.358039 Acc: 0.2005\n",
      "Elapsed 604.00s, 60.40 s/epoch, 0.29 s/batch, ets 5436.02s\n",
      "Stepping scheduler this epoch.  LR: [6.382393305518408e-05]\n",
      "\n",
      "Test set: Average loss: 2.6926, Accuracy: 137/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6990, Accuracy: 144/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.698973, \n",
      "Initial Test Accuracy : 8.791%\n",
      "\n",
      "Epoch: 10 \n",
      "Train Loss: 2.348491 Acc: 0.2085\n",
      "Elapsed 665.01s, 60.46 s/epoch, 0.29 s/batch, ets 5380.55s\n",
      "Stepping scheduler this epoch.  LR: [6.127097573297672e-05]\n",
      "\n",
      "Test set: Average loss: 2.7284, Accuracy: 159/1638 (10%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7324, Accuracy: 155/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.732426, \n",
      "Initial Test Accuracy : 9.463%\n",
      "\n",
      "Epoch: 11 \n",
      "Train Loss: 2.332493 Acc: 0.2130\n",
      "Elapsed 726.11s, 60.51 s/epoch, 0.30 s/batch, ets 5324.80s\n",
      "Stepping scheduler this epoch.  LR: [5.882013670365765e-05]\n",
      "\n",
      "Test set: Average loss: 2.7327, Accuracy: 149/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7301, Accuracy: 150/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.730101, \n",
      "Initial Test Accuracy : 9.158%\n",
      "\n",
      "Epoch: 12 \n",
      "Train Loss: 2.335754 Acc: 0.2056\n",
      "Elapsed 786.56s, 60.50 s/epoch, 0.30 s/batch, ets 5263.91s\n",
      "Stepping scheduler this epoch.  LR: [5.6467331235511337e-05]\n",
      "\n",
      "Test set: Average loss: 2.6946, Accuracy: 146/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.6857, Accuracy: 148/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.685659, \n",
      "Initial Test Accuracy : 9.035%\n",
      "\n",
      "Epoch: 13 \n",
      "Train Loss: 2.316128 Acc: 0.2160\n",
      "Elapsed 847.63s, 60.54 s/epoch, 0.30 s/batch, ets 5206.86s\n",
      "Stepping scheduler this epoch.  LR: [5.4208637986090884e-05]\n",
      "\n",
      "Test set: Average loss: 2.7547, Accuracy: 151/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7518, Accuracy: 148/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.751796, \n",
      "Initial Test Accuracy : 9.035%\n",
      "\n",
      "Epoch: 14 \n",
      "Train Loss: 2.326934 Acc: 0.2122\n",
      "Elapsed 908.27s, 60.55 s/epoch, 0.30 s/batch, ets 5146.85s\n",
      "Stepping scheduler this epoch.  LR: [5.2040292466647244e-05]\n",
      "\n",
      "Test set: Average loss: 2.7038, Accuracy: 142/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7083, Accuracy: 140/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.708332, \n",
      "Initial Test Accuracy : 8.547%\n",
      "\n",
      "Epoch: 15 \n",
      "Train Loss: 2.325205 Acc: 0.2160\n",
      "Elapsed 969.79s, 60.61 s/epoch, 0.30 s/batch, ets 5091.41s\n",
      "Stepping scheduler this epoch.  LR: [4.995868076798135e-05]\n",
      "\n",
      "Test set: Average loss: 2.7349, Accuracy: 152/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7332, Accuracy: 153/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.733191, \n",
      "Initial Test Accuracy : 9.341%\n",
      "\n",
      "Epoch: 16 \n",
      "Train Loss: 2.300484 Acc: 0.2255\n",
      "Elapsed 1031.80s, 60.69 s/epoch, 0.30 s/batch, ets 5037.61s\n",
      "Stepping scheduler this epoch.  LR: [4.7960333537262095e-05]\n",
      "\n",
      "Test set: Average loss: 2.7397, Accuracy: 137/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7422, Accuracy: 142/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.742209, \n",
      "Initial Test Accuracy : 8.669%\n",
      "\n",
      "Epoch: 17 \n",
      "Train Loss: 2.295264 Acc: 0.2227\n",
      "Elapsed 1094.50s, 60.81 s/epoch, 0.30 s/batch, ets 4986.04s\n",
      "Stepping scheduler this epoch.  LR: [4.6041920195771606e-05]\n",
      "\n",
      "Test set: Average loss: 2.8063, Accuracy: 155/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7917, Accuracy: 144/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.791651, \n",
      "Initial Test Accuracy : 8.791%\n",
      "\n",
      "Epoch: 18 \n",
      "Train Loss: 2.300246 Acc: 0.2195\n",
      "Elapsed 1156.29s, 60.86 s/epoch, 0.30 s/batch, ets 4929.43s\n",
      "Stepping scheduler this epoch.  LR: [4.420024338794074e-05]\n",
      "\n",
      "Test set: Average loss: 2.7887, Accuracy: 149/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7831, Accuracy: 158/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.783104, \n",
      "Initial Test Accuracy : 9.646%\n",
      "\n",
      "Epoch: 19 \n",
      "Train Loss: 2.285926 Acc: 0.2207\n",
      "Elapsed 1217.82s, 60.89 s/epoch, 0.30 s/batch, ets 4871.30s\n",
      "Stepping scheduler this epoch.  LR: [4.243223365242311e-05]\n",
      "\n",
      "Test set: Average loss: 2.7352, Accuracy: 130/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7400, Accuracy: 157/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.740043, \n",
      "Initial Test Accuracy : 9.585%\n",
      "\n",
      "Epoch: 20 \n",
      "Train Loss: 2.289129 Acc: 0.2227\n",
      "Elapsed 1279.59s, 60.93 s/epoch, 0.30 s/batch, ets 4813.68s\n",
      "Stepping scheduler this epoch.  LR: [4.073494430632618e-05]\n",
      "\n",
      "Test set: Average loss: 2.7228, Accuracy: 140/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7208, Accuracy: 134/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.720779, \n",
      "Initial Test Accuracy : 8.181%\n",
      "\n",
      "Epoch: 21 \n",
      "Train Loss: 2.296208 Acc: 0.2160\n",
      "Elapsed 1341.72s, 60.99 s/epoch, 0.30 s/batch, ets 4757.01s\n",
      "Stepping scheduler this epoch.  LR: [3.910554653407313e-05]\n",
      "\n",
      "Test set: Average loss: 2.7349, Accuracy: 147/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7381, Accuracy: 156/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.738132, \n",
      "Initial Test Accuracy : 9.524%\n",
      "\n",
      "Epoch: 22 \n",
      "Train Loss: 2.286580 Acc: 0.2284\n",
      "Elapsed 1403.54s, 61.02 s/epoch, 0.30 s/batch, ets 4698.80s\n",
      "Stepping scheduler this epoch.  LR: [3.7541324672710204e-05]\n",
      "\n",
      "Test set: Average loss: 2.7696, Accuracy: 154/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7785, Accuracy: 153/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.778458, \n",
      "Initial Test Accuracy : 9.341%\n",
      "\n",
      "Epoch: 23 \n",
      "Train Loss: 2.280716 Acc: 0.2223\n",
      "Elapsed 1464.71s, 61.03 s/epoch, 0.30 s/batch, ets 4638.25s\n",
      "Stepping scheduler this epoch.  LR: [3.603967168580179e-05]\n",
      "\n",
      "Test set: Average loss: 2.7480, Accuracy: 135/1638 (8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7364, Accuracy: 142/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.736373, \n",
      "Initial Test Accuracy : 8.669%\n",
      "\n",
      "Epoch: 24 \n",
      "Train Loss: 2.264638 Acc: 0.2285\n",
      "Elapsed 1526.04s, 61.04 s/epoch, 0.30 s/batch, ets 4578.12s\n",
      "Stepping scheduler this epoch.  LR: [3.459808481836972e-05]\n",
      "\n",
      "Test set: Average loss: 2.7429, Accuracy: 141/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7359, Accuracy: 147/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.735877, \n",
      "Initial Test Accuracy : 8.974%\n",
      "\n",
      "Epoch: 25 \n",
      "Train Loss: 2.285186 Acc: 0.2252\n",
      "Elapsed 1587.04s, 61.04 s/epoch, 0.30 s/batch, ets 4516.96s\n",
      "Stepping scheduler this epoch.  LR: [3.321416142563493e-05]\n",
      "\n",
      "Test set: Average loss: 2.7905, Accuracy: 146/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7868, Accuracy: 148/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.786830, \n",
      "Initial Test Accuracy : 9.035%\n",
      "\n",
      "Epoch: 26 \n",
      "Train Loss: 2.292473 Acc: 0.2171\n",
      "Elapsed 1648.33s, 61.05 s/epoch, 0.30 s/batch, ets 4456.58s\n",
      "Stepping scheduler this epoch.  LR: [3.188559496860953e-05]\n",
      "\n",
      "Test set: Average loss: 2.7593, Accuracy: 151/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7819, Accuracy: 153/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.781923, \n",
      "Initial Test Accuracy : 9.341%\n",
      "\n",
      "Epoch: 27 \n",
      "Train Loss: 2.261068 Acc: 0.2291\n",
      "Elapsed 1709.16s, 61.04 s/epoch, 0.30 s/batch, ets 4394.99s\n",
      "Stepping scheduler this epoch.  LR: [3.0610171169865154e-05]\n",
      "\n",
      "Test set: Average loss: 2.7881, Accuracy: 149/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7941, Accuracy: 146/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.794136, \n",
      "Initial Test Accuracy : 8.913%\n",
      "\n",
      "Epoch: 28 \n",
      "Train Loss: 2.256027 Acc: 0.2303\n",
      "Elapsed 1771.24s, 61.08 s/epoch, 0.30 s/batch, ets 4336.47s\n",
      "Stepping scheduler this epoch.  LR: [2.9385764323070547e-05]\n",
      "\n",
      "Test set: Average loss: 2.7932, Accuracy: 152/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7925, Accuracy: 162/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.792515, \n",
      "Initial Test Accuracy : 9.890%\n",
      "\n",
      "Epoch: 29 \n",
      "Train Loss: 2.272482 Acc: 0.2245\n",
      "Elapsed 1832.05s, 61.07 s/epoch, 0.30 s/batch, ets 4274.79s\n",
      "Stepping scheduler this epoch.  LR: [2.8210333750147723e-05]\n",
      "\n",
      "Test set: Average loss: 2.7984, Accuracy: 148/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7984, Accuracy: 150/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.798428, \n",
      "Initial Test Accuracy : 9.158%\n",
      "\n",
      "Epoch: 30 \n",
      "Train Loss: 2.260936 Acc: 0.2284\n",
      "Elapsed 1892.91s, 61.06 s/epoch, 0.30 s/batch, ets 4213.25s\n",
      "Stepping scheduler this epoch.  LR: [2.7081920400141814e-05]\n",
      "\n",
      "Test set: Average loss: 2.7895, Accuracy: 158/1638 (10%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7918, Accuracy: 152/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.791761, \n",
      "Initial Test Accuracy : 9.280%\n",
      "\n",
      "Epoch: 31 \n",
      "Train Loss: 2.268395 Acc: 0.2244\n",
      "Elapsed 1954.35s, 61.07 s/epoch, 0.30 s/batch, ets 4152.99s\n",
      "Stepping scheduler this epoch.  LR: [2.599864358413614e-05]\n",
      "\n",
      "Test set: Average loss: 2.7604, Accuracy: 146/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7784, Accuracy: 140/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.778387, \n",
      "Initial Test Accuracy : 8.547%\n",
      "\n",
      "Epoch: 32 \n",
      "Train Loss: 2.262388 Acc: 0.2313\n",
      "Elapsed 2014.93s, 61.06 s/epoch, 0.30 s/batch, ets 4090.91s\n",
      "Stepping scheduler this epoch.  LR: [2.4958697840770694e-05]\n",
      "\n",
      "Test set: Average loss: 2.8136, Accuracy: 150/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8065, Accuracy: 144/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.806484, \n",
      "Initial Test Accuracy : 8.791%\n",
      "\n",
      "Epoch: 33 \n",
      "Train Loss: 2.261289 Acc: 0.2277\n",
      "Elapsed 2075.58s, 61.05 s/epoch, 0.30 s/batch, ets 4029.07s\n",
      "Stepping scheduler this epoch.  LR: [2.3960349927139864e-05]\n",
      "\n",
      "Test set: Average loss: 2.7639, Accuracy: 149/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7730, Accuracy: 138/1638 (8%)\n",
      "\n",
      "Initial Test Loss : 2.772966, \n",
      "Initial Test Accuracy : 8.425%\n",
      "\n",
      "Epoch: 34 \n",
      "Train Loss: 2.245110 Acc: 0.2271\n",
      "Elapsed 2137.38s, 61.07 s/epoch, 0.30 s/batch, ets 3969.43s\n",
      "Stepping scheduler this epoch.  LR: [2.3001935930054268e-05]\n",
      "\n",
      "Test set: Average loss: 2.8126, Accuracy: 155/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7933, Accuracy: 143/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.793297, \n",
      "Initial Test Accuracy : 8.730%\n",
      "\n",
      "Epoch: 35 \n",
      "Train Loss: 2.244088 Acc: 0.2305\n",
      "Elapsed 2198.60s, 61.07 s/epoch, 0.30 s/batch, ets 3908.63s\n",
      "Stepping scheduler this epoch.  LR: [2.2081858492852098e-05]\n",
      "\n",
      "Test set: Average loss: 2.8166, Accuracy: 150/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8125, Accuracy: 161/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.812460, \n",
      "Initial Test Accuracy : 9.829%\n",
      "\n",
      "Epoch: 36 \n",
      "Train Loss: 2.239468 Acc: 0.2299\n",
      "Elapsed 2259.26s, 61.06 s/epoch, 0.30 s/batch, ets 3846.85s\n",
      "Stepping scheduler this epoch.  LR: [2.1198584153138014e-05]\n",
      "\n",
      "Test set: Average loss: 2.8059, Accuracy: 144/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8111, Accuracy: 152/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.811096, \n",
      "Initial Test Accuracy : 9.280%\n",
      "\n",
      "Epoch: 37 \n",
      "Train Loss: 2.250301 Acc: 0.2291\n",
      "Elapsed 2319.87s, 61.05 s/epoch, 0.30 s/batch, ets 3785.05s\n",
      "Stepping scheduler this epoch.  LR: [2.035064078701249e-05]\n",
      "\n",
      "Test set: Average loss: 2.7836, Accuracy: 141/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.7843, Accuracy: 148/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.784313, \n",
      "Initial Test Accuracy : 9.035%\n",
      "\n",
      "Epoch: 38 \n",
      "Train Loss: 2.243310 Acc: 0.2354\n",
      "Elapsed 2385.00s, 61.15 s/epoch, 0.30 s/batch, ets 3730.39s\n",
      "Stepping scheduler this epoch.  LR: [1.953661515553199e-05]\n",
      "\n",
      "Test set: Average loss: 2.8008, Accuracy: 148/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8004, Accuracy: 153/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.800391, \n",
      "Initial Test Accuracy : 9.341%\n",
      "\n",
      "Epoch: 39 \n",
      "Train Loss: 2.237936 Acc: 0.2290\n",
      "Elapsed 2446.74s, 61.17 s/epoch, 0.30 s/batch, ets 3670.10s\n",
      "Stepping scheduler this epoch.  LR: [1.8755150549310708e-05]\n",
      "\n",
      "Test set: Average loss: 2.8281, Accuracy: 148/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8289, Accuracy: 156/1638 (10%)\n",
      "\n",
      "Initial Test Loss : 2.828897, \n",
      "Initial Test Accuracy : 9.524%\n",
      "\n",
      "Epoch: 40 \n",
      "Train Loss: 2.235654 Acc: 0.2343\n",
      "Elapsed 2509.67s, 61.21 s/epoch, 0.30 s/batch, ets 3611.47s\n",
      "Stepping scheduler this epoch.  LR: [1.800494452733828e-05]\n",
      "\n",
      "Test set: Average loss: 2.8499, Accuracy: 150/1638 (9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 2.8545, Accuracy: 141/1638 (9%)\n",
      "\n",
      "Initial Test Loss : 2.854529, \n",
      "Initial Test Accuracy : 8.608%\n",
      "\n",
      "Epoch: 41 \n",
      "Train Loss: 2.238982 Acc: 0.2370\n",
      "Elapsed 2572.23s, 61.24 s/epoch, 0.30 s/batch, ets 3552.13s\n",
      "Stepping scheduler this epoch.  LR: [1.7284746746244747e-05]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6c74ffbcf422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train and validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-3ddc1a2f12f7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, optimizer, scheduler, system_configuration, training_configuration, data_augmentation)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtraining_configuration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mepoch_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-19de18b981c9>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(train_config, model, test_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcount_corect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mindx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate\n",
    "model, train_loss, train_acc, val_loss, val_acc = main(model, optimizer, scheduler=scheduler, data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss=[train_loss], \n",
    "                   val_loss=[val_loss], \n",
    "                   train_acc=[train_acc], \n",
    "                   val_acc=[val_acc], \n",
    "                   colors=['blue'], \n",
    "                   loss_legend_loc='upper center', \n",
    "                   acc_legend_loc='upper left')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_loader, test_loader = get_data(\n",
    "        batch_size=train_config.batch_size,\n",
    "        data_root=train_config.data_root,\n",
    "        num_workers=train_config.num_workers,\n",
    "        data_augmentation=True\n",
    "    )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "truelabels = []\n",
    "predictions = []\n",
    "\n",
    "classes = classesArray\n",
    "\n",
    "for data, target in test_loader:\n",
    "    for label in target.cpu().data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n",
    "\n",
    "Share your tensorboard scalars logs link in this section. You can also share (not mandatory) your GitHub link if you have pushed this project in GitHub. \n",
    "\n",
    "For example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "Share your Kaggle profile link here with us so that we can give points for the competition score. \n",
    "\n",
    "https://www.kaggle.com/alanhaugen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
