{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods that will be used to get training and validation data loader.\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "def get_data(args1, *agrs):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics libraries for python\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classesArray = [] # hack\n",
    "        \n",
    "class FoodDataset(Dataset):\n",
    "    \"\"\"\n",
    "    This custom dataset class take root directory and train flag, \n",
    "    and return dataset training dataset id train flag is true \n",
    "    else is return validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, train=True, image_shape=None, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        init method of the class.\n",
    "        \n",
    "         Parameters:\n",
    "         \n",
    "         data_root (string): path of root directory.\n",
    "         \n",
    "         train (boolean): True for training dataset and False for test dataset.\n",
    "         \n",
    "         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n",
    "                                             It is not None image will resize to the given shape.\n",
    "                                 \n",
    "         transform (method): method that will take PIL image and transforms it.\n",
    "         \n",
    "        \"\"\"\n",
    "        \n",
    "        # get label to class mapping\n",
    "        if train:\n",
    "            label_csv_path = os.path.join(data_root, 'train.csv')\n",
    "        else:\n",
    "            label_csv_path = os.path.join(data_root, 'sample_submission.csv') # test.csv? Does not have classes...\n",
    "        \n",
    "        img_dir = os.path.join(data_root, 'images', 'images')\n",
    "        \n",
    "        self.label_df = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "        \n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "            'label': []\n",
    "        }\n",
    "        \n",
    "        # Dirty. Maybe train_test_split from sklearn would be a better option\n",
    "        for i, table in self.label_df.iterrows():\n",
    "            img = table['id']\n",
    "            className = table['class']\n",
    "            if className not in classesArray:\n",
    "                classesArray.append(className)\n",
    "            classNumber = classesArray.index(className)\n",
    "            img_path  = os.path.join(img_dir, str(img) + '.jpg')\n",
    "            self.data_dict['image_path'].append(img_path)\n",
    "            self.data_dict['label'].append(classNumber)\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['label'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        image = Image.open(self.data_dict['image_path'][idx])\n",
    "        \n",
    "        print(\"DEBUG:\")\n",
    "        print(self.data_dict['image_path'][idx])\n",
    "        \n",
    "        if self.image_shape is not None:\n",
    "            image = image.resize(self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        target = self.data_dict['label'][idx]\n",
    "        \n",
    "        return image, target            \n",
    "                \n",
    "        \n",
    "    def get_id(self, label):\n",
    "        \"\"\"\n",
    "        class label to common name mapping\n",
    "        \"\"\"\n",
    "        return self.label_df['id'][label]\n",
    "    \n",
    "    def get_class(self, label):\n",
    "        \"\"\"\n",
    "        class label to latin name mapping\n",
    "        \"\"\"\n",
    "        return self.label_df['class'][label]\n",
    "\n",
    "def get_data(batch_size, data_root, tb_writer, num_workers=4, data_augmentation=False):\n",
    "    mean, std = get_mean_std(data_root=data_root, num_workers=num_workers)\n",
    "    \n",
    "    common_transforms = image_common_transforms(mean, std)\n",
    "   \n",
    "    # if data_augmentation is true \n",
    "    # data augmentation implementation\n",
    "    if data_augmentation:    \n",
    "        train_transforms = data_augmentation_preprocess(mean, std)\n",
    "    # else do common transforms\n",
    "    else:\n",
    "        train_transforms = common_transforms\n",
    "    \n",
    "       \n",
    "    # train dataloader\n",
    "    \n",
    "    trainDataset = FoodDataset(data_root, train=True, image_shape=256, transform=train_transforms)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(trainDataset, \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=True,\n",
    "                               num_workers=num_workers)\n",
    "    \n",
    "    # test dataloader\n",
    "    \n",
    "    testDataset = FoodDataset(data_root, train=False, image_shape=256, transform=train_transforms)\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(testDataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=num_workers)\n",
    "    \n",
    "    add_data_embeddings(testDataset, tb_writer, n=100)\n",
    "    \n",
    "    print('Length of the dataset: {}'.format(len(trainDataset)))\n",
    "\n",
    "    img, trgt = trainDataset[300]\n",
    "\n",
    "    print('Label: {}, id: {}, class: {}'.format(trgt, trainDataset.get_id(trgt), \n",
    "                                                              trainDataset.get_class(trgt)))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot few images\n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 9)\n",
    "    plt.figure\n",
    "    for images, labels in test_loader:\n",
    "        for i in range(len(labels)):\n",
    "            plt.subplot(3, 5, i+1)\n",
    "            img = transforms.functional.to_pil_image(images[i])\n",
    "            plt.imshow(img)\n",
    "            plt.gca().set_title('Target: {0}'.format(labels[i]))\n",
    "        plt.show()\n",
    "        break\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "Define your configuration in this section.\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"./cat-dog-panda\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 100  # number of times the whole dataset will be passed through the network\n",
    "    init_learning_rate: float = 0.0001  # determines the speed of network's weights update\n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"../data\" \n",
    "    num_workers: int = 10  # number of concurrent processes using to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard\n",
    "def prediction(model, device, batch_input, max_prob=True):\n",
    "    \"\"\"\n",
    "    get prediction for batch inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    # send model to cpu/cuda according to your system configuration\n",
    "    model.to(device)\n",
    "    \n",
    "    # it is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "\n",
    "    data = batch_input.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "    \n",
    "    if max_prob:\n",
    "        # get the max probability\n",
    "        pred_prob = prob.data.max(dim=1)[0]\n",
    "    else:\n",
    "        pred_prob = prob.data\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()\n",
    "\n",
    "def get_target_and_prob(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    get targets and prediction probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_prob = []\n",
    "    targets = []\n",
    "    \n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        \n",
    "        _, prob = prediction(model, device, data, max_prob=False)\n",
    "        \n",
    "        pred_prob.append(prob)\n",
    "        \n",
    "        target = target.numpy()\n",
    "        targets.append(target)\n",
    "        \n",
    "    targets = np.concatenate(targets)\n",
    "    targets = targets.astype(int)\n",
    "    pred_prob = np.concatenate(pred_prob, axis=0)\n",
    "    \n",
    "    return targets, pred_prob\n",
    "\n",
    "def get_random_inputs_labels(inputs, targets, n=100):\n",
    "    \"\"\"\n",
    "    get random inputs and labels\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(inputs) == len(targets)\n",
    "\n",
    "    rand_indices = torch.randperm(len(targets))\n",
    "    \n",
    "    data = inputs[rand_indices][:n]\n",
    "    \n",
    "    labels = targets[rand_indices][:n]\n",
    "    \n",
    "    class_labels = [classesArray[lab] for lab in labels]\n",
    "    \n",
    "    return data, class_labels\n",
    "\n",
    "def add_data_embeddings(dataset, tb_writer, n=100):\n",
    "    \"\"\"\n",
    "    Add a few inputs and labels to tensorboard. \n",
    "    \"\"\"\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=n, num_workers=4, shuffle=True)\n",
    "    \n",
    "    images, labels = next(iter(dataloader))\n",
    "    \n",
    "    tb_writer.add_embedding(mat = images.view(-1, 3 * 224 * 224), \n",
    "                            metadata=labels, \n",
    "                            label_img=images)\n",
    "    \n",
    "    return\n",
    "\n",
    "def add_pr_curves_to_tensorboard(model, dataloader, device, tb_writer, epoch, num_classes=10):\n",
    "    \"\"\"\n",
    "    Add precession and recall curve to tensorboard.\n",
    "    \"\"\"\n",
    "    \n",
    "    targets, pred_prob = get_target_and_prob(model, dataloader, device)\n",
    "    \n",
    "    for cls_idx in range(num_classes):\n",
    "        binary_target = targets == cls_idx\n",
    "        true_prediction_prob = pred_prob[:, cls_idx]\n",
    "        \n",
    "        tb_writer.add_pr_curve(classesArray[cls_idx], \n",
    "                               binary_target, \n",
    "                               true_prediction_prob, \n",
    "                               global_step=epoch)\n",
    "        \n",
    "    return\n",
    "\n",
    "def add_wrong_prediction_to_tensorboard(data_root, model, dataloader, device, tb_writer, \n",
    "                                        epoch, tag='Wrong_Predections', max_images='all'):\n",
    "    \"\"\"\n",
    "    Add wrong predicted images to tensorboard.\n",
    "    \"\"\"\n",
    "    #number of images in one row\n",
    "    num_images_per_row = 8\n",
    "    im_scale = 3\n",
    "    \n",
    "    plot_images = []\n",
    "    wrong_labels = []\n",
    "    pred_prob = []\n",
    "    right_label = []\n",
    "    \n",
    "    mean, std = get_mean_std(data_root)\n",
    "    \n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        images = data.numpy()\n",
    "        pred, prob = prediction(model, device, data)\n",
    "        target = target.numpy()\n",
    "        indices = pred.astype(int) != target.astype(int)\n",
    "        \n",
    "        plot_images.append(images[indices])\n",
    "        wrong_labels.append(pred[indices])\n",
    "        pred_prob.append(prob[indices])\n",
    "        right_label.append(target[indices])\n",
    "        \n",
    "    plot_images = np.concatenate(plot_images, axis=0).squeeze()\n",
    "    plot_images = (np.moveaxis(plot_images, 1, -1) * std) + mean\n",
    "    print('plot_images.shape: {}'.format(plot_images.shape))\n",
    "    print(plot_images.min())\n",
    "    print(plot_images.max())\n",
    "    wrong_labels = np.concatenate(wrong_labels)\n",
    "    wrong_labels = wrong_labels.astype(int)\n",
    "    right_label = np.concatenate(right_label)\n",
    "    right_label = right_label.astype(int)\n",
    "    pred_prob = np.concatenate(pred_prob)\n",
    "    \n",
    "    \n",
    "    if max_images == 'all':\n",
    "        num_images = len(images)\n",
    "    else:\n",
    "        num_images = min(len(plot_images), max_images)\n",
    "        \n",
    "    fig_width = num_images_per_row * im_scale\n",
    "    \n",
    "    if num_images % num_images_per_row == 0:\n",
    "        num_row = num_images/num_images_per_row\n",
    "    else:\n",
    "        num_row = int(num_images/num_images_per_row) + 1\n",
    "        \n",
    "    fig_height = num_row * im_scale\n",
    "        \n",
    "    plt.style.use('default')\n",
    "    plt.rcParams[\"figure.figsize\"] = (fig_width, fig_height)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(num_row, num_images_per_row, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(plot_images[i].astype('uint8'))\n",
    "        plt.gca().set_title('{0}({1:.2}), {2}'.format(animal_classes[wrong_labels[i]], \n",
    "                                                          pred_prob[i], \n",
    "                                                          animal_classes[right_label[i]]))\n",
    "        \n",
    "    tb_writer.add_figure(tag, fig, global_step=epoch)\n",
    "    \n",
    "    return\n",
    "\n",
    "def add_pr_curves_to_tensorboard(model, dataloader, device, tb_writer, epoch, num_classes=3):\n",
    "    \"\"\"\n",
    "    Add precession and recall curve to tensorboard.\n",
    "    \"\"\"\n",
    "    \n",
    "    targets, pred_prob = get_target_and_prob(model, dataloader, device)\n",
    "    \n",
    "    for cls_idx in range(num_classes):\n",
    "        binary_target = targets == cls_idx\n",
    "        true_prediction_prob = pred_prob[:, cls_idx]\n",
    "        \n",
    "        tb_writer.add_pr_curve(classesArray[cls_idx], \n",
    "                               binary_target, \n",
    "                               true_prediction_prob, \n",
    "                               global_step=epoch)\n",
    "        \n",
    "    return\n",
    "\n",
    "def add_model_weights_as_histogram(model, tb_writer, epoch):\n",
    "    for name, param in model.named_parameters():\n",
    "        tb_writer.add_histogram(name.replace('.', '/'), param.data.cpu().abs(), epoch)\n",
    "    return\n",
    "\n",
    "def add_network_graph_tensorboard(model, inputs, tb_writer):\n",
    "    tb_writer.add_graph(model, inputs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "Define methods or classes that will be used in model evaluation—for example, accuracy, f1-score, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_loss, val_loss, train_acc, val_acc, colors, \n",
    "                       loss_legend_loc='upper center', acc_legend_loc='upper left', \n",
    "                       fig_size=(20, 10), sub_plot1=(1, 2, 1), sub_plot2=(1, 2, 2)):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.subplot(sub_plot1[0], sub_plot1[1], sub_plot1[2])\n",
    "    \n",
    "    for i in range(len(train_loss)):\n",
    "        x_train = range(len(train_loss[i]))\n",
    "        x_val = range(len(val_loss[i]))\n",
    "        \n",
    "        min_train_loss = train_loss[i].min()\n",
    "        \n",
    "        min_val_loss = val_loss[i].min()\n",
    "        \n",
    "        plt.plot(x_train, train_loss[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN LOSS ({0:.4})\".format(min_train_loss))\n",
    "        plt.plot(x_val, val_loss[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID LOSS ({0:.4})\".format(min_val_loss))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc=loss_legend_loc)\n",
    "    plt.title('Training and Validation Loss')\n",
    "        \n",
    "    plt.subplot(sub_plot2[0], sub_plot2[1], sub_plot2[2])\n",
    "    \n",
    "    for i in range(len(train_acc)):\n",
    "        x_train = range(len(train_acc[i]))\n",
    "        x_val = range(len(val_acc[i]))\n",
    "        \n",
    "        max_train_acc = train_acc[i].max() \n",
    "        \n",
    "        max_val_acc = val_acc[i].max() \n",
    "        \n",
    "        plt.plot(x_train, train_acc[i], linestyle='-', color='tab:{}'.format(colors[i]), \n",
    "                 label=\"TRAIN ACC ({0:.4})\".format(max_train_acc))\n",
    "        plt.plot(x_val, val_acc[i], linestyle='--' , color='tab:{}'.format(colors[i]), \n",
    "                 label=\"VALID ACC ({0:.4})\".format(max_val_acc))\n",
    "        \n",
    "    plt.xlabel('epoch no.')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=acc_legend_loc)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    fig.savefig('sample_loss_acc_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, device, model_dir='../models', model_file_name='food_classifier.pt'):\n",
    "    \n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # make sure you transfer the model to cpu.\n",
    "    if device == 'cuda':\n",
    "        model.to('cpu')\n",
    "\n",
    "    # save the state_dict\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        model.to('cuda')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='../models', model_file_name='food_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "Write the methods or classes that will be used for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    # \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    for data, target in test_loader:\n",
    "        indx_target = target.clone()\n",
    "        data = data.to(train_config.device)\n",
    "        \n",
    "        target = target.to(train_config.device)\n",
    "        \n",
    "        output = model(data)\n",
    "        # add loss for each mini batch\n",
    "        test_loss += F.cross_entropy(output, target).item()\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1] \n",
    "        \n",
    "        # add correct prediction count\n",
    "        count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "    # average over number of mini-batches\n",
    "    test_loss = test_loss / len(test_loader)  \n",
    "    \n",
    "    # average over number of dataset\n",
    "    accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "    \n",
    "    print(\n",
    "        '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int, tb_writer: SummaryWriter\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mood\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "       \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gardients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # Score to probability using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "        \n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:\n",
    "            \n",
    "            total_batch = epoch_idx * len(train_loader.dataset)/train_config.batch_size + batch_idx\n",
    "            tb_writer.add_scalar('Loss/train-batch', loss.item(), total_batch)\n",
    "            tb_writer.add_scalar('Accuracy/train-batch', acc, total_batch)\n",
    "    \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    print('Epoch: {} \\nTrain Loss: {:.6f} Acc: {:.4f}'.format(epoch_idx, epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "Define your model in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 256x256x3\n",
    "classes = 13\n",
    "nodes = 128\n",
    "k = 1\n",
    "\n",
    "#nn.BatchNorm2d(64),\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(16 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16 * k, out_channels=32 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(32 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32 * k, out_channels=64 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(64 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64 * k, out_channels=128 * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(128 * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128 * k, out_channels=nodes * k, kernel_size=3),\n",
    "            nn.BatchNorm2d(nodes * k),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Linear(in_features=3200 * k, out_features=10), \n",
    "            nn.Dropout(0.5), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=10, out_features=classes)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir='../models', model_file_name='food_classifier.pt'):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, optimizer, scheduler=None, system_configuration=SystemConfiguration(), \n",
    "         training_configuration=TrainingConfiguration(), data_augmentation=True):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # Tensorboard writer for visualization\n",
    "    tb_writer = SummaryWriter('../logs/kenyan_food_log')\n",
    "    \n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lowers batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 4\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        tb_writer=tb_writer,\n",
    "        num_workers=num_workers_to_set,\n",
    "        data_augmentation=data_augmentation\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    #add_wrong_prediction_to_tensorboard(training_configuration.data_root,\n",
    "    #                                    model,\n",
    "    #                                    test_loader, \n",
    "    #                                    training_configuration.device, \n",
    "    #                                    tb_writer,\n",
    "    #                                    0,\n",
    "    #                                    max_images=300)\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        # Calculate Initial Test Loss\n",
    "        init_val_loss, init_val_accuracy = validate(training_configuration, model, test_loader)\n",
    "        print(\"Initial Test Loss : {:.6f}, \\nInitial Test Accuracy : {:.3f}%\\n\".format(init_val_loss, init_val_accuracy*100))\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch, tb_writer)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "        \n",
    "        # add scalar (loss/accuracy) to tensorboard\n",
    "        tb_writer.add_scalar('Loss/Train',train_loss, epoch)\n",
    "        tb_writer.add_scalar('Accuracy/Train', train_acc, epoch)\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        # add time metadata to tensorboard\n",
    "        tb_writer.add_scalar('Time/elapsed_time', elapsed_time, epoch)\n",
    "        tb_writer.add_scalar('Time/speed_epoch', speed_epoch, epoch)\n",
    "        tb_writer.add_scalar('Time/speed_batch', speed_batch, epoch)\n",
    "        tb_writer.add_scalar('Time/eta', eta, epoch)\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            # add scalar (loss/accuracy) to tensorboard\n",
    "            tb_writer.add_scalar('Loss/Validation', current_loss, epoch)\n",
    "            tb_writer.add_scalar('Accuracy/Validation', current_accuracy, epoch)\n",
    "            \n",
    "            # add scalars (loss/accuracy) to tensorboard\n",
    "            tb_writer.add_scalars('Loss/train-val', {'train': train_loss, \n",
    "                                           'validation': current_loss}, epoch)\n",
    "            tb_writer.add_scalars('Accuracy/train-val', {'train': train_acc, \n",
    "                                               'validation': current_accuracy}, epoch)\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                print('Model Improved. Saving the Model...\\n')\n",
    "                save_model(model, device=training_configuration.device)\n",
    "                \n",
    "            # add wrong predicted image to tensorboard\n",
    "            #add_wrong_prediction_to_tensorboard(training_configuration.data_root,\n",
    "            #                                    model,\n",
    "            #                                    test_loader, \n",
    "            #                                    training_configuration.device, \n",
    "            #                                    tb_writer,\n",
    "            #                                    epoch,\n",
    "            #                                    max_images=300)\n",
    "        \n",
    "        # Decay learning rate\n",
    "        if scheduler is not None:\n",
    "            scheduler.step() # scheduler step/ update learning rate\n",
    "            print('Stepping scheduler this epoch. ', 'LR:', scheduler.get_lr())\n",
    " \n",
    "        add_model_weights_as_histogram(model, tb_writer, epoch)\n",
    "    \n",
    "        # add pr curves to tensor board\n",
    "        add_pr_curves_to_tensorboard(model, test_loader, \n",
    "                                     training_configuration.device, \n",
    "                                     tb_writer, epoch, num_classes=3)\n",
    "        \n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "Define your methods or classes which are not covered in the above sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess_transforms():\n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms\n",
    "\n",
    "def data_augmentation_preprocess(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_preprocess_transforms()\n",
    "    \n",
    "    data_augmentation_transforms = transforms.Compose([\n",
    "        torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomRotation(20),\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return data_augmentation_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(data_root, num_workers=4):\n",
    "    \n",
    "    transform = image_preprocess_transforms()\n",
    "    training_configuration = TrainingConfiguration()\n",
    "    \n",
    "    file_path = os.path.join(data_root, 'images')\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=file_path, transform=transform)\n",
    "    \n",
    "    loader = torch.utils.data.DataLoader(dataset, \n",
    "                                         batch_size=training_configuration.batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=True)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    \n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "    \n",
    "    print('mean: {}, std: {}'.format(mean, std))\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "Choose your optimizer and LR-scheduler and use the above methods and classes to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#model = MyModel()\n",
    "model = torchvision.models.resnet50()\n",
    "\n",
    "print(model)\n",
    "\n",
    "# get optimizer\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=train_config.init_learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# optimizer\n",
    "#optimizer = optim.Adam(\n",
    "#    model.parameters(),\n",
    "#    lr = train_config.init_learning_rate\n",
    "#)\n",
    "\n",
    "#scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "decayRate = 0.96\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decayRate)\n",
    "\n",
    "#optimizer = optim.SGD(\n",
    "#    model.parameters(),\n",
    "#    lr=train_config.init_learning_rate\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.5767, 0.4626, 0.3468]), std: tensor([0.2383, 0.2463, 0.2465])\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/2224981444106704933.jpg\n",
      "../data/images/images/8610771667677140612.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/7872954221890963019.jpg\n",
      "../data/images/images/10339228361504636930.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15420066193900048627.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1253171383327810313.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8963499626222449785.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13030798924629492933.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3146403483459214329.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/15984341305404319383.jpg\n",
      "../data/images/images/10053968366178130571.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5704150953485322846.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11914821150418780901.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1809594897324964994.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3767803558849581161.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16003046902247218372.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6123138375555250273.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10167444174484939993.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13740848199373029732.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9262750812933300107.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17288124010928133768.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6246759883907852128.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13938600820860208169.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17752160307677920947.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3396833193198700680.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3711403687064729885.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6232636558598944983.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/9424367005659488848.jpg\n",
      "../data/images/images/5053722403418721391.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2297886573487684944.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16613706322518465182.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14982433425707378904.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4514822777811323246.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18133551717905815019.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4404476756115290291.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10980071427192134186.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9483664308571127021.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13495864791665742259.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8070398107115864960.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2247466778915529376.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1863175047210509183.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/1173020092299634974.jpg\n",
      "../data/images/images/9836734105723430015.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10255648894052535135.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7787602503367496997.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/17207040581827766683.jpg\n",
      "../data/images/images/16863679609295193704.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13493423979918447741.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1682467021062503279.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5634936085032883235.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6919287004125397271.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11091193550656819941.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/17542312725499552915.jpg\n",
      "../data/images/images/8075343263870747236.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14381175113183798313.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2097783291071828587.jpg\n",
      "DEBUG:\n",
      "../data/images/images/512923677288863455.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/6682507767458170780.jpg\n",
      "../data/images/images/13500013090806477875.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3400137384372973994.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17811283064377029460.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7292013769757473790.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/7408919968790131218.jpg\n",
      "../data/images/images/8026531078427276542.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9549488084638141068.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18403896937644910866.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13319384938647182256.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/4081630355592203827.jpg\n",
      "../data/images/images/17787049892774459992.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/14474177846666819107.jpg\n",
      "../data/images/images/17194171674521480016.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12890258924022188867.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/17918549253947459126.jpg\n",
      "../data/images/images/16968451424473401787.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8171659330960222196.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13479425059802666179.jpg\n",
      "../data/images/images/1014758634312903488.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3793125430018403920.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13392872177502096557.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13452690258779666660.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15784926491953258851.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7221783998263486163.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4269292328271167690.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5027742189550437393.jpg\n",
      "DEBUG:\n",
      "../data/images/images/51494649589090308.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4628206316993090341.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/11641094941268581672.jpg\n",
      "../data/images/images/8959879861829815440.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15791639334496722722.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18338581703934103416.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16856439956069557065.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6809160214341311484.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4781079925672478992.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2600769511702945169.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4076570994290712712.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4711036524470639280.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4115855569707467526.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/4015243674580015337.jpg\n",
      "../data/images/images/9412204221775165702.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/8494908487746813132.jpg\n",
      "../data/images/images/15343688871541190605.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16733507603041909653.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7208747626207752318.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/17093341382563500450.jpg\n",
      "../data/images/images/1697974532803824405.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14113208918002127606.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7041581166084582091.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4177592678758114705.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14644963988026730156.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18107350579341218870.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8924339916156119511.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3697052806271570355.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1151340011619121945.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4013878968969303649.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6175923175697524236.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/9418712822200217869.jpg\n",
      "../data/images/images/1268853060970168600.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13967636354169271196.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14507826452339696121.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/15721642928858865483.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5910870249936252255.jpg\n",
      "../data/images/images/1308405771024117947.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/18033263504731551310.jpg\n",
      "../data/images/images/8436191237338367818.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7454000247671709039.jpg\n",
      "DEBUG:\n",
      "../data/images/images/699206164563426944.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1190904870294331237.jpg\n",
      "DEBUG:\n",
      "../data/images/images/230968931011229920.jpg\n",
      "DEBUG:\n",
      "../data/images/images/825702726106671707.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17265890521318489894.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4321845221603757100.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/2613711888083304420.jpg\n",
      "../data/images/images/9147118515029059717.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12413229900846481172.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/7058867706280603036.jpg\n",
      "../data/images/images/1327679144513531403.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6392045152143226394.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17720302108385555487.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3647449053075634130.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8678673742576225342.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15236417011922871300.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8482449136638770916.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3580451554644108530.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16952847848158134734.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7100011903375021356.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17268932542209018929.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2075669848385099186.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2445750027843907911.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4288033394674623641.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15577853985026801001.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16727233800936938420.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4019893388986937213.jpg\n",
      "DEBUG:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/images/images/9345882131302789141.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11056899456295591592.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13250687501080686233.jpg\n",
      "../data/images/images/8330809471224801845.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13334162841330420370.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/15307304429787502647.jpg\n",
      "../data/images/images/1761202656439641211.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14698117972999685745.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14542278034613981489.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11686084625492414640.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9177832684280818731.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11213160321815852433.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12304585492801821345.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5664138533187591675.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5532429127410230523.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10210408058411103472.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10417553581850764656.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5273979289374794223.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6512875783777128377.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14975855235003076153.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10984765358796854556.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5398584390448294216.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5532447134573461004.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9605848492862836796.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8409839621855699938.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8127640645858525485.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9464277099030727272.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13651203668939430381.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9732487811157129771.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15413941144267748757.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2970146313928564521.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10146855953709637313.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6317831331282602489.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/6835424573932973161.jpg\n",
      "../data/images/images/8864144451303122104.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14579203465964835328.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/12190482841788287969.jpg\n",
      "../data/images/images/4662318703558052158.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5098735543608280733.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13688545282406807934.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3260325480167148205.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9983143109257055319.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17432578408954224623.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/4453944119038229285.jpg\n",
      "../data/images/images/11272422573892563227.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2344461873770014309.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14954270823585947476.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8366853423763282151.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14508043394830310397.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9610706368676739838.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4481342611008844605.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6704970097468892762.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13036738916593120738.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1255838052347703913.jpg\n",
      "../data/images/images/7448314752935014867.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16215118427448248795.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14542091352150712102.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1618978818159102165.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11454517292593001511.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14784080218898399737.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15544679750857647773.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14068111136860818040.jpg\n",
      "DEBUG:\n",
      "../data/images/images/634042432987635792.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11562798857806808660.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/3173247370964915065.jpg\n",
      "../data/images/images/4736115185826833796.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2898165480889255917.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5677145000661758740.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/3592778677403097463.jpg\n",
      "../data/images/images/1609143050607389938.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/10475097977441005546.jpg\n",
      "../data/images/images/16628438556945881387.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/12283929423234404748.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12422873183785263624.jpg\n",
      "../data/images/images/1956655081026942891.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11326839832877371856.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12563942188259613277.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12070983743458305916.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6817907151647124825.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18361632310508725159.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1106694991546983314.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/14396271323363876211.jpg\n",
      "../data/images/images/3358463591943382311.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4308109774443930579.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11723940602129810871.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/14821606558201435649.jpg\n",
      "../data/images/images/13783194148085135188.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1780765580077424678.jpg\n",
      "DEBUG:\n",
      "../data/images/images/963922924980847426.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8818144310971459792.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16405252168285728336.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2860081108466158644.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12295810728359605251.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13395793322365795428.jpg\n",
      "../data/images/images/9470207748503241447.jpg\n",
      "DEBUG:\n",
      "../data/images/images/691689698043245695.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14907600478035390244.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8122302957309708656.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/16359624726774465653.jpg\n",
      "../data/images/images/11535783017487666377.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10050515638223314442.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10339445144891593406.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/1923401634727571601.jpg\n",
      "../data/images/images/17427226605692675584.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14794431530485533532.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11648134672858840143.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11886108908787234100.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11337580954633840380.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/18284473261399416282.jpg\n",
      "../data/images/images/15270725996382649745.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11134487749526925893.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2447819354520689764.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/4146008112016168642.jpg\n",
      "../data/images/images/9454800986798553859.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4725812552826592991.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12823018413701037577.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/12572693452350169998.jpg\n",
      "../data/images/images/14409722843287822376.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3128739111728374700.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8442556265306306568.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18401324197708093617.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8982974588876029828.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/1864727275683354447.jpg\n",
      "../data/images/images/5042902231190736409.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/11690744022751122119.jpg\n",
      "../data/images/images/7498296764986325048.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17224247491032553528.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18130385372494771245.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13130517454188646276.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13941062316169308071.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15525226038135404760.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/8061768398722356164.jpg\n",
      "../data/images/images/9537299342678615272.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8169398357497609509.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4815300026156414451.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/16064694664829207474.jpg\n",
      "../data/images/images/8199546024210931840.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15010453219563633688.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5842161939701625540.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11933447057896498110.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/9718148789833698568.jpg\n",
      "../data/images/images/15611581128678721814.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14588723242839554524.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15246833662796709148.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11660516594270309605.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13316308935725775772.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/15307323044021690827.jpg\n",
      "../data/images/images/11152145487391213387.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6047348548014323691.jpg\n",
      "../data/images/images/9831451002903685171.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/7090335710586585180.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12177996140980390810.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10980185564964092888.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16330529712295811220.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "../data/images/images/10205244452050272005.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/21777686455352971.jpg\n",
      "../data/images/images/15998400115613049600.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8542395356535003059.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15242087691161580527.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4005754432901553386.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5516465342013907071.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9141685386751923865.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5299368598670376053.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9987748929643127811.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11351098185926786646.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1138106990904529981.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7276441722201816177.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15529833818405966637.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13280393165872350073.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15617575508956638548.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5617948646673360638.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/971150236775003747.jpg\n",
      "../data/images/images/16516137224955958547.jpg\n",
      "../data/images/images/7861531088572184030.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12462405995319637502.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/2471255497063470064.jpg\n",
      "../data/images/images/12586310520313462797.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13738694436628663675.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2091586883237847738.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15837883805851084503.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14360740897193017434.jpg\n",
      "DEBUG:\n",
      "../data/images/images/570418296745250296.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5528771884209068889.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/3599007874642349329.jpg\n",
      "../data/images/images/5906402380945584030.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7864121173869884240.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18035688642552147908.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10364628891292215286.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8082017208962233056.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17564317916912636892.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13437902355558957450.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/4574080512455162074.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/5803177950092770827.jpg\n",
      "../data/images/images/13132651776640899968.jpg\n",
      "../data/images/images/4731425001968148142.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18204843003659860818.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3320564052696386260.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13727972974186781687.jpg\n",
      "../data/images/images/4017085193156170180.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/2787489864413511046.jpg\n",
      "../data/images/images/13172261710344007662.jpg\n",
      "DEBUG:\n",
      "../data/images/images/190583790112789153.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16892044434778607840.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/5849146165974862944.jpg\n",
      "../data/images/images/17582687004008127199.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15332892200993368190.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2930459753345228850.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2045401121454521681.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9963874194584857281.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13614126059644421646.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13405159931727864910.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17511719856616651463.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5640441215423128996.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15196825795726720908.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8103186216717651954.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17434792391398283853.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8878583122904013188.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/3760226432429706262.jpg\n",
      "../data/images/images/14689699371785903046.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8172558162846207490.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5069828705950569129.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12762109995665584616.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17744659393778354376.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/13206921344428048576.jpg\n",
      "../data/images/images/13202364408612726373.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5690943988096131409.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16014255725798508949.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9798429900990795864.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5401219456540441384.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16761524033244008930.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/383985176186318350.jpg\n",
      "../data/images/images/1006060013086312085.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18345681561108186439.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14156508233128764200.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9173210393871356667.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13106084860451128932.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14028842691736739333.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7966594966604130128.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17850164114256913036.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3325918639776174273.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5724468328178054074.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6935090551980744441.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1261318722338624942.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2008482944638019636.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13745924057774526623.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5030324776614681870.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12893931851747442508.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13928378446623884919.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4367770269008602819.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1876803055874027339.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15499739773845712139.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11899337070914149329.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12814409014851519046.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7632548321121845670.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12429188656729245881.jpg\n",
      "DEBUG:\n",
      "../data/images/images/54261387083828189.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11853808499021519488.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12467060892843811929.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7364447289823250077.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14651396983149172235.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5301403657601924172.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18256609712454655569.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10102135989223399039.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11044581937949087098.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8224140705519034519.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2919934771304300737.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4295620720041118240.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7885935125002285873.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7471730227220449048.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17210534352979300296.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16957067880792897424.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11273007305087293207.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5134535133102715871.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1704933171119356655.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1332419927557888525.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17937127923183919409.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12796141440678518689.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14171265242887745988.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7691051705431832854.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15911324942732885782.jpg\n",
      "DEBUG:\n",
      "../data/images/images/672727354585566109.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13046092059779174320.jpg\n",
      "DEBUG:\n",
      "../data/images/images/73585503001692948.jpg\n",
      "DEBUG:\n",
      "../data/images/images/563134102082537349.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1454430129030544281.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9419250458836193428.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6482224277738774779.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7046126591494148881.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12117591841116020342.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8981686928535387831.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11967373751660434844.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10256780869845093755.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15977602221596961242.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7731995542456206558.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12344218208966038964.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/17128961191243831995.jpg\n",
      "../data/images/images/10700319438606129328.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11633379313373654772.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9477063447395541099.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/5293350080522344635.jpg\n",
      "../data/images/images/292802461187707446.jpg\n",
      "DEBUG:\n",
      "../data/images/images/573125046587835375.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4344362503327457770.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2431745078513709323.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1844495863342443673.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6555923592586729371.jpg\n",
      "DEBUG:\n",
      "../data/images/images/104956647675820356.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12364679000028286569.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "../data/images/images/1475593175992332077.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1868109317692894922.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11609818703397893644.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7678641842478065807.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4194396063119815321.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17914231228109970366.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17076771111771916276.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4297934370841092623.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3741678571648944754.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7596800488769036423.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15756845896695767480.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8330157423714725352.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1085792071419706511.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13373868820710903194.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17647919880829694060.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14301458430728614216.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16430359035991942160.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4893338428504341540.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/16284339368408617325.jpg\n",
      "../data/images/images/7543536850118167079.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13030474542176117586.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8191689196361054462.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18309647083736534668.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10221522431636914443.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10954539690037219490.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3631180427842360203.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9744777344956312944.jpg\n",
      "DEBUG:\n",
      "../data/images/images/647900954527732216.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9407793000171090428.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4483848793587466732.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9843029272490566120.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10320356927600389905.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8936543358036618968.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9650672577969928643.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15612062029096667719.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6396591038294174819.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6774158799031929280.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1315418192411844186.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9987632807364869709.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16777923082017237424.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15799150417003083830.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5554288459467044185.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5991642280840420094.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13439795037187141784.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3042354874029001686.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10373288511046020375.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2556254428325141139.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17696150560205563525.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5626538573426609586.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5377424266929477918.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16423264267335797272.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16941361751969582812.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16530947211268098698.jpg\n",
      "DEBUG:\n",
      "../data/images/images/743012228932996608.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/16900522038743265235.jpg\n",
      "../data/images/images/16469299669885562719.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13552367371481848242.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12687387531012590726.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15690765801804992630.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15403420818112465789.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14885818782999856641.jpg\n",
      "DEBUG:\n",
      "../data/images/images/14977836354102447397.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7596268598227627643.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10480333472611798096.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9455622265043837393.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9886588510475065022.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1874263454507016479.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15975300486287559149.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16362870378604418258.jpg\n",
      "DEBUG:\n",
      "../data/images/images/107237062910247483.jpg\n",
      "DEBUG:\n",
      "../data/images/images/626209249074323498.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7190465626661991478.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8131343961915104980.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11456538388715881358.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13211555919876126779.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15781013442978420992.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12228548014114347637.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10803788572811639770.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12835348423889232535.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10748063253389367191.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6314096715012043755.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16271962796057438680.jpg\n",
      "DEBUG:\n",
      "../data/images/images/411417267119446365.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3495662739256532804.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7903242276198010604.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11797153860402397545.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11554647870369242755.jpg\n",
      "DEBUG:\n",
      "DEBUG:\n",
      "../data/images/images/1674572457225651955.jpg\n",
      "../data/images/images/13507811531970908780.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1370022267746356756.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5329791121973914714.jpg\n",
      "DEBUG:\n",
      "../data/images/images/13229977937927150508.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3739531203182583081.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2473792716552828424.jpg\n",
      "DEBUG:\n",
      "../data/images/images/7181469353547598878.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5963029213602578163.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15781707531856133212.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18007961739551904029.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11626675398845327226.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4695272267228050823.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4664626221851502202.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16683593917678038805.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2126561920171109649.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10551512450149335925.jpg\n",
      "DEBUG:\n",
      "../data/images/images/9056719094847129624.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18004644678378107263.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8074959968013521342.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11857063416583993569.jpg\n",
      "DEBUG:\n",
      "../data/images/images/18103661662374264683.jpg\n",
      "DEBUG:\n",
      "../data/images/images/8465211282352040108.jpg\n",
      "DEBUG:\n",
      "../data/images/images/16088305652519027380.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6036690809816550455.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10850480463793081851.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4274441265593863943.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1686713138475937211.jpg\n",
      "DEBUG:\n",
      "../data/images/images/63625948565734799.jpg\n",
      "DEBUG:\n",
      "../data/images/images/378295533330079115.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5119270676735881810.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1820280516107246454.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10061861767693484137.jpg\n",
      "DEBUG:\n",
      "../data/images/images/4710262463064487129.jpg\n",
      "DEBUG:\n",
      "../data/images/images/15294536547736352103.jpg\n",
      "DEBUG:\n",
      "../data/images/images/930236947628925041.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5166134352301815123.jpg\n",
      "DEBUG:\n",
      "../data/images/images/6381810042027465099.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1338531362454450346.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11274329368194161236.jpg\n",
      "DEBUG:\n",
      "../data/images/images/5778209842554051444.jpg\n",
      "DEBUG:\n",
      "../data/images/images/10748354524868351672.jpg\n",
      "DEBUG:\n",
      "../data/images/images/17254491036980948864.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2982179634770272328.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1722419049703004856.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12749715907909482115.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11020565079782254191.jpg\n",
      "DEBUG:\n",
      "../data/images/images/2551679508373319620.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1174247532507103283.jpg\n",
      "DEBUG:\n",
      "../data/images/images/1952725610792777429.jpg\n",
      "DEBUG:\n",
      "../data/images/images/3212144336039033436.jpg\n",
      "DEBUG:\n",
      "../data/images/images/11540687631499223797.jpg\n",
      "DEBUG:\n",
      "../data/images/images/12339291527051578818.jpg\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "Length of the dataset: 6536\n",
      "DEBUG:\n",
      "../data/images/images/12427539806364778611.jpg\n",
      "Label: 4, id: 2547906925836120627, class: matoke\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 224, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6c74ffbcf422>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train and validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-5a781fe8505d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, optimizer, scheduler, system_configuration, training_configuration, data_augmentation)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtb_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_writer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers_to_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8d4e20b30d9b>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(batch_size, data_root, tb_writer, num_workers, data_augmentation)\u001b[0m\n\u001b[1;32m    150\u001b[0m     print('Label: {}, id: {}, class: {}'.format(trgt, trainDataset.get_id(trgt), \n\u001b[1;32m    151\u001b[0m                                                               trainDataset.get_class(trgt)))\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2681\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2682\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2683\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2684\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5669\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5671\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5672\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    688\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    689\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 690\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 224, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMmUlEQVR4nO3bYYjkd33H8ffHXFNpGrWYFeTuNJFeqtdQiF3SFKFGTMslhbsnIncQWkvw0Br7QCmkWFKJjxppBeFae7QSFTSePqiLnAS0EYt4mg3R6F24sj1ts0SaU9M8EY2h3z6Y0U7mu3v7v8vszC19v2Bh/v/5zex3h7n3/ue//0tVIUmTXrToASRdfgyDpMYwSGoMg6TGMEhqDIOkZsswJPlokqeSfGeT+5Pkw0nWkjyW5PWzH1PSPA05YrgfOHCB+28D9o2/jgJ//8LHkrRIW4ahqr4C/OgCSw4BH6+RU8DLkrxyVgNKmr9dM3iO3cATE9vr433fn16Y5Cijowquuuqq337ta187g28vaTOPPPLID6pq6WIfN4swZIN9G15nXVXHgeMAy8vLtbq6OoNvL2kzSf7jUh43i79KrAN7J7b3AE/O4HklLcgswrAC/NH4rxM3A89UVfsYIWnn2PKjRJJPAbcA1yRZB/4K+CWAqvoIcBK4HVgDfgz8yXYNK2k+tgxDVR3Z4v4C3jWziSQtnFc+SmoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagaFIcmBJGeTrCW5e4P7X5XkoSSPJnksye2zH1XSvGwZhiRXAMeA24D9wJEk+6eW/SVwoqpuBA4DfzfrQSXNz5AjhpuAtao6V1XPAg8Ah6bWFPCS8e2XAk/ObkRJ8zYkDLuBJya218f7Jr0fuCPJOnASePdGT5TkaJLVJKvnz5+/hHElzcOQMGSDfTW1fQS4v6r2ALcDn0jSnruqjlfVclUtLy0tXfy0kuZiSBjWgb0T23voHxXuBE4AVNXXgBcD18xiQEnzNyQMDwP7klyX5EpGJxdXptb8J/BmgCSvYxQGPytIO9SWYaiq54C7gAeBxxn99eF0knuTHBwvey/w9iTfAj4FvK2qpj9uSNohdg1ZVFUnGZ1UnNx3z8TtM8AbZjuapEXxykdJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQMCkOSA0nOJllLcvcma96a5EyS00k+OdsxJc3Trq0WJLkCOAb8PrAOPJxkparOTKzZB/wF8IaqejrJK7ZrYEnbb8gRw03AWlWdq6pngQeAQ1Nr3g4cq6qnAarqqdmOKWmehoRhN/DExPb6eN+k64Hrk3w1yakkBzZ6oiRHk6wmWT1//vylTSxp2w0JQzbYV1Pbu4B9wC3AEeAfk7ysPajqeFUtV9Xy0tLSxc4qaU6GhGEd2DuxvQd4coM1n6uqn1XVd4GzjEIhaQcaEoaHgX1JrktyJXAYWJla88/AmwCSXMPoo8W5WQ4qaX62DENVPQfcBTwIPA6cqKrTSe5NcnC87EHgh0nOAA8Bf15VP9yuoSVtr1RNny6Yj+Xl5VpdXV3I95b+v0jySFUtX+zjvPJRUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSMygMSQ4kOZtkLcndF1j3liSVZHl2I0qaty3DkOQK4BhwG7AfOJJk/wbrrgb+DPj6rIeUNF9DjhhuAtaq6lxVPQs8ABzaYN0HgPuAn8xwPkkLMCQMu4EnJrbXx/t+IcmNwN6q+vyFnijJ0SSrSVbPnz9/0cNKmo8hYcgG++oXdyYvAj4EvHerJ6qq41W1XFXLS0tLw6eUNFdDwrAO7J3Y3gM8ObF9NXAD8OUk3wNuBlY8ASntXEPC8DCwL8l1Sa4EDgMrP7+zqp6pqmuq6tqquhY4BRysqtVtmVjSttsyDFX1HHAX8CDwOHCiqk4nuTfJwe0eUNL87RqyqKpOAien9t2zydpbXvhYkhbJKx8lNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVIzKAxJDiQ5m2Qtyd0b3P+eJGeSPJbkS0lePftRJc3LlmFIcgVwDLgN2A8cSbJ/atmjwHJV/RbwWeC+WQ8qaX6GHDHcBKxV1bmqehZ4ADg0uaCqHqqqH483TwF7ZjumpHkaEobdwBMT2+vjfZu5E/jCRnckOZpkNcnq+fPnh08paa6GhCEb7KsNFyZ3AMvABze6v6qOV9VyVS0vLS0Nn1LSXO0asGYd2DuxvQd4cnpRkluB9wFvrKqfzmY8SYsw5IjhYWBfkuuSXAkcBlYmFyS5EfgH4GBVPTX7MSXN05ZhqKrngLuAB4HHgRNVdTrJvUkOjpd9EPhV4DNJvplkZZOnk7QDDPkoQVWdBE5O7btn4vatM55L0gJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiSHEhyNslakrs3uP+Xk3x6fP/Xk1w760Elzc+WYUhyBXAMuA3YDxxJsn9q2Z3A01X168CHgL+e9aCS5mfIEcNNwFpVnauqZ4EHgENTaw4BHxvf/izw5iSZ3ZiS5mnXgDW7gScmtteB39lsTVU9l+QZ4OXADyYXJTkKHB1v/jTJdy5l6AW5hqmf5zK2k2aFnTXvTpoV4Dcu5UFDwrDRb/66hDVU1XHgOECS1apaHvD9Lws7ad6dNCvsrHl30qwwmvdSHjfko8Q6sHdiew/w5GZrkuwCXgr86FIGkrR4Q8LwMLAvyXVJrgQOAytTa1aAPx7ffgvwL1XVjhgk7QxbfpQYnzO4C3gQuAL4aFWdTnIvsFpVK8A/AZ9IssboSOHwgO99/AXMvQg7ad6dNCvsrHl30qxwifPGX+ySpnnlo6TGMEhqtj0MO+ly6gGzvifJmSSPJflSklcvYs6JeS4478S6tySpJAv7M9uQWZO8dfz6nk7yyXnPODXLVu+FVyV5KMmj4/fD7YuYczzLR5M8tdl1QRn58PhneSzJ67d80qrati9GJyv/HXgNcCXwLWD/1Jo/BT4yvn0Y+PR2zvQCZ30T8Cvj2+9c1KxD5x2vuxr4CnAKWL5cZwX2AY8CvzbefsXl/NoyOqn3zvHt/cD3Fjjv7wGvB76zyf23A19gdL3RzcDXt3rO7T5i2EmXU285a1U9VFU/Hm+eYnRNx6IMeW0BPgDcB/xknsNNGTLr24FjVfU0QFU9NecZJw2Zt4CXjG+/lH5tz9xU1Ve48HVDh4CP18gp4GVJXnmh59zuMGx0OfXuzdZU1XPAzy+nnrchs066k1GFF2XLeZPcCOytqs/Pc7ANDHltrweuT/LVJKeSHJjbdN2Qed8P3JFkHTgJvHs+o12Si31vD7ok+oWY2eXUczB4jiR3AMvAG7d1ogu74LxJXsTof7q+bV4DXcCQ13YXo48TtzA6EvvXJDdU1X9v82wbGTLvEeD+qvqbJL/L6DqeG6rqf7Z/vIt20f/GtvuIYSddTj1kVpLcCrwPOFhVP53TbBvZat6rgRuALyf5HqPPlisLOgE59H3wuar6WVV9FzjLKBSLMGTeO4ETAFX1NeDFjP6D1eVo0Hv7ebb5pMgu4BxwHf93Euc3p9a8i+effDyxoBM4Q2a9kdFJqX2LmPFi551a/2UWd/JxyGt7APjY+PY1jA59X34Zz/sF4G3j268b/0PLAt8P17L5ycc/5PknH7+x5fPNYeDbgX8b/4N633jfvYx+48KotJ8B1oBvAK9Z4Iu71axfBP4L+Ob4a2VRsw6Zd2rtwsIw8LUN8LfAGeDbwOHL+bVl9JeIr46j8U3gDxY466eA7wM/Y3R0cCfwDuAdE6/tsfHP8u0h7wMviZbUeOWjpMYwSGoMg6TGMEhqDIOkxjBIagyDpOZ/AS9qX9SUF4NfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train and validate\n",
    "model, train_loss, train_acc, val_loss, val_acc = main(model, optimizer, scheduler=scheduler, data_augmentation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss=[train_loss], \n",
    "                   val_loss=[val_loss], \n",
    "                   train_acc=[train_acc], \n",
    "                   val_acc=[val_acc], \n",
    "                   colors=['blue'], \n",
    "                   loss_legend_loc='upper center', \n",
    "                   acc_legend_loc='upper left')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_loader, test_loader = get_data(\n",
    "        batch_size=train_config.batch_size,\n",
    "        data_root=train_config.data_root,\n",
    "        num_workers=train_config.num_workers,\n",
    "        data_augmentation=True\n",
    "    )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "truelabels = []\n",
    "predictions = []\n",
    "\n",
    "classes = classesArray\n",
    "\n",
    "for data, target in test_loader:\n",
    "    for label in target.cpu().data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model.cpu()(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n",
    "\n",
    "Share your tensorboard scalars logs link in this section. You can also share (not mandatory) your GitHub link if you have pushed this project in GitHub. \n",
    "\n",
    "For example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/alanhaugen/pytorch-opencv-course-classification\n",
    "\n",
    "[Find Project2 logs here](https://tensorboard.dev/experiment/IKzTP79DTNaUYpWi3wlsbg)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "Share your Kaggle profile link here with us so that we can give points for the competition score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/alanhaugen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "conda-env-py37_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
